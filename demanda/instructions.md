# Instructions to download DEMANDA

There are several files in this directory:

- `getJSON.py`: breaks up a date range in 6-day slots (max days permitted by the CENACE API and generates the corresponding list of urls in the required format). Prints to stdout.
- `downloadJSON.py`: Given a list of urls (generated by	`getJSON.py`), downloads the individual JSON files into its own `result_${index}.json` file (I can't remember why this didn't work with a bash curl loop).
- `zonemap.py`: This file does all the processing. Takes a JSON as input (you also pass in an `output_name.csv`), converts the `Valores` column into a pandas data frame, maps the `zona_carga` to its corresponding ID in the database (using a dictionary defined in the file), renames teh columns, sets them in the correct order and builds the combined DF for all of the nodes in the JSON file, then prints it out to `output_name.csv`. 
- `runall.sh`: Bash script that runs `zonemap.py` for all the `result_*.json` files in the directory. Could potentially do this in Python as well.


We need the files in CSV format (and clean) because that's how we'll upload them into the database.


## Step-by-step guide

1. Set the date range in the `getJSON.py` file. Generate the url list and pipe it out into a file.

```bash
> python getJSON.py > urls.txt
```

2. Convert the file to unix line endings (just in case) using `dos2unix` in the command line.

```bash
> dos2unix urls.txt
```

3. Download the actual data using `downloadJSON.py`.

```bash
> python downloadJSON.py urls.txt
```

4. Run runall.sh to convert all of the JSONs into a well-formatted CSV.

```bash
> bash runall.sh
```

5. Combine them all into a single file

```bash
> cat *.csv > result.csv
```

6. Ready to upload to DB.

